{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = np.array([\n",
    "    [1, 0], [-1, 0], [0, 1], [0, -1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Map:\n",
    "    color_list = {10: 'blue', 1: 'orange', 0: 'g', -1: 'y', -100: 'r'}\n",
    "\n",
    "    def __init__(self, height, width, negative_rate, cliff_rate):\n",
    "        # All empty\n",
    "        self.game_map = np.zeros((height, width))\n",
    "\n",
    "        # Add random negative terrain AND cliff\n",
    "        total = height*width\n",
    "        negative_num = int(negative_rate*total)\n",
    "        cliff_num = int(cliff_rate*total)\n",
    "        li = np.random.choice(range(total), negative_num+cliff_num)\n",
    "        for i in li[0:negative_num]:\n",
    "            self.game_map[i//width][i % width] = -1\n",
    "        for i in li[negative_num:]:\n",
    "            self.game_map[i//width][i % width] = -100\n",
    "\n",
    "        # Start and end points are always 0\n",
    "        self.game_map[0][0] = 1\n",
    "        self.game_map[height-1][width-1] = 10\n",
    "\n",
    "    # function to add grid\n",
    "    def fill_grid(self, x, y, xw, yw, color):\n",
    "        plt.fill_between(np.linspace(x-xw, x+xw, 10),\n",
    "                         y+yw, y-yw, \n",
    "                         facecolor=color)\n",
    "        return\n",
    "    \n",
    "    # funcion to draw a arrow\n",
    "    def draw_arrow(self, x, y, d_x, d_y, size, color):\n",
    "        plt.quiver(x-d_x*size, y-d_y*size, \n",
    "                    d_x*size*2, d_y *size*2,\n",
    "                    units='xy', scale=1, color=color)\n",
    "        return\n",
    "\n",
    "    def display_gamemap(self):\n",
    "        plt.figure(figsize=(9, 3))\n",
    "        \n",
    "        # int -> color\n",
    "        for i in range(self.game_map.shape[0]):\n",
    "            for j in range(self.game_map.shape[1]):\n",
    "                self.fill_grid(j+1, i+1,\n",
    "                               0.48, 0.48, \n",
    "                               self.color_list[self.game_map[i][j]])\n",
    "\n",
    "        plt.yticks(np.arange(1, self.game_map.shape[0]+1, 1))\n",
    "        plt.xticks(np.arange(1, self.game_map.shape[1]+1, 1))\n",
    "        plt.show()\n",
    "        return\n",
    "\n",
    "    def display_gamemap_and_arrows(self, guide):\n",
    "        plt.figure(figsize=(9, 3))\n",
    "            \n",
    "        # int -> color\n",
    "        for i in range(self.game_map.shape[0]):\n",
    "            for j in range(self.game_map.shape[1]):\n",
    "                self.fill_grid(j+1, i+1, \n",
    "                               0.48, 0.48, \n",
    "                               self.color_list[self.game_map[i][j]])\n",
    "                self.draw_arrow(j+1,i+1,\n",
    "                        actions[guide[i][j]][1], actions[guide[i][j]][0],\n",
    "                        0.4, 'black')\n",
    "\n",
    "        plt.yticks(np.arange(1, self.game_map.shape[0]+1, 1))\n",
    "        plt.xticks(np.arange(1, self.game_map.shape[1]+1, 1))\n",
    "\n",
    "\n",
    "game_map = Map(4, 12, 0.3, 0.1)\n",
    "game_map.display_gamemap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SARSA:\n",
    "    epsilon = 0.4\n",
    "    alpha = 0.0002\n",
    "    gamma = 0.98\n",
    "    TotalSteps = 400000\n",
    "    TtoC = {1:-1, 10:-1, 0:-1, -1:-5, -100:-100}\n",
    "\n",
    "    def __init__(self, game_map, actions) -> None:\n",
    "        self.game_map = game_map\n",
    "        self.BeginPoint = np.array([0, 0])\n",
    "        self.EndPoint = np.array([game_map.shape[0]-1, game_map.shape[1]-1])\n",
    "        self.actions = actions\n",
    "        self.Q = np.zeros((game_map.shape[0], game_map.shape[1], actions.shape[0]))\n",
    "        return\n",
    "\n",
    "    # return the index of selected action\n",
    "    def epsilon_greedy(self, pos) -> int:\n",
    "        Q_actions = self.Q[pos[0]][pos[1]]\n",
    "        if self.epsilon < np.random.rand():\n",
    "            return np.argmax(Q_actions)\n",
    "        else:\n",
    "            return random.sample(range(len(Q_actions)), 1)[0]\n",
    "\n",
    "    def nexts(self, s1, act_index) -> np.array:\n",
    "        s2 = s1+self.actions[act_index]\n",
    "        s2[0] = np.clip(s2[0], 0, self.game_map.shape[0]-1)\n",
    "        s2[1] = np.clip(s2[1], 0, self.game_map.shape[1]-1)\n",
    "        return s2\n",
    "\n",
    "    def Reward(self, dst) -> int:\n",
    "        return self.TtoC[self.game_map[dst[0]][dst[1]]]\n",
    "\n",
    "    def update(self) -> None:\n",
    "        List = []\n",
    "        success = []\n",
    "        Record = []\n",
    "        for episode in range(1, self.TotalSteps+1):\n",
    "\n",
    "            s1 = np.array([0, 0])\n",
    "            SUM = 0\n",
    "            lenth = 0\n",
    "            while True:\n",
    "                s1_act_index = self.epsilon_greedy(s1)\n",
    "                s2 = self.nexts(s1, s1_act_index)\n",
    "                reward = self.Reward(s2)\n",
    "                s2_act_index = self.epsilon_greedy(s2)\n",
    "\n",
    "                SUM += reward\n",
    "                lenth += 1\n",
    "\n",
    "                q1 = self.Q[s1[0]][s1[1]][s1_act_index]\n",
    "                q2 = self.Q[s2[0]][s2[1]][s2_act_index]\n",
    "\n",
    "                # TD_error=Q_now-TD_target\n",
    "                TD_error = q1-(reward+self.gamma*q2)\n",
    "\n",
    "                self.Q[s1[0]][s1[1]][s1_act_index] -= self.alpha*TD_error\n",
    "                s1 = s2.copy()\n",
    "\n",
    "                if self.game_map[s1[0]][s1[1]] == -100 or lenth > 100:\n",
    "                    success.append(0)\n",
    "                    break\n",
    "                elif self.game_map[s1[0]][s1[1]] == 10:\n",
    "                    success.append(1)\n",
    "                    break\n",
    "\n",
    "            List.append(SUM)\n",
    "            if episode % 1000 == 0:\n",
    "                self.epsilon *= 0.99\n",
    "                Record.append(np.average(List[-1000:]))\n",
    "                print('Train ---- episode={}, ave_successes={:.3f} ave_reward={:.3f} '.format(\n",
    "                    episode,\n",
    "                    np.average(success[-1000:]),\n",
    "                    Record[-1])\n",
    "                )\n",
    "        return Record\n",
    "\n",
    "    # output\n",
    "    def get_guide(self) -> np.array:\n",
    "        guides = np.zeros(self.game_map.shape)\n",
    "        for i in range(guides.shape[0]):\n",
    "            for j in range(guides.shape[1]):\n",
    "                guides[i][j] = np.argmax(self.Q[i][j])\n",
    "        return guides.astype(np.int32)\n",
    "\n",
    "\n",
    "sarsa = SARSA(game_map.game_map, actions)\n",
    "SList = sarsa.update()\n",
    "Sguide = sarsa.get_guide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(SList)\n",
    "plt.xlabel('episodes(x1000)')\n",
    "plt.ylabel('Reward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_map.display_gamemap_and_arrows(Sguide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Muti_SARSA:\n",
    "    epsilon = 0.4\n",
    "    alpha = 0.0002\n",
    "    gamma = 0.98\n",
    "    TotalSteps = 400000\n",
    "    TtoC = {1:-1, 10:-1, 0:-1, -1:-5, -100:-100}\n",
    "\n",
    "    def __init__(self,game_map,actions) -> None:\n",
    "        self.game_map=game_map\n",
    "        self.BeginPoint=np.array([0,0])\n",
    "        self.EndPoint=np.array([game_map.shape[0]-1,game_map.shape[1]-1])\n",
    "        self.actions=actions\n",
    "        self.Q=np.zeros((game_map.shape[0],game_map.shape[1],actions.shape[0]))\n",
    "        return\n",
    "    \n",
    "    # return the index of selected action\n",
    "    def epsilon_greedy(self,pos) -> int:\n",
    "        Q_actions=self.Q[pos[0]][pos[1]]\n",
    "        if self.epsilon<np.random.rand():\n",
    "            return np.argmax(Q_actions)\n",
    "        else:\n",
    "            return random.sample(range(len(Q_actions)),1)[0]\n",
    "    \n",
    "    def nexts(self,s1,act_index) -> np.array:\n",
    "        s2=s1+self.actions[act_index]\n",
    "        s2[0]=np.clip(s2[0],0,self.game_map.shape[0]-1)\n",
    "        s2[1]=np.clip(s2[1],0,self.game_map.shape[1]-1)\n",
    "        return s2\n",
    "\n",
    "    def Reward(self,dst) -> int:\n",
    "        return self.TtoC[self.game_map[dst[0]][dst[1]]]\n",
    "\n",
    "    def update(self) -> None:\n",
    "        List=[]\n",
    "        success=[]\n",
    "        Record=[]\n",
    "        for episode in range(1,self.TotalSteps+1):\n",
    "\n",
    "            s1=np.array([0,0])\n",
    "            SUM=0\n",
    "            lenth=0\n",
    "            while True:\n",
    "                s1_act_index=self.epsilon_greedy(s1)\n",
    "                s2=self.nexts(s1,s1_act_index)\n",
    "                reward1=self.Reward(s2)\n",
    "\n",
    "                s2_act_index=self.epsilon_greedy(s2)\n",
    "                s3=self.nexts(s2,s2_act_index)\n",
    "                reward2=self.Reward(s3)\n",
    "\n",
    "                s3_act_index=self.epsilon_greedy(s3)\n",
    "                s4=self.nexts(s3,s3_act_index)\n",
    "                reward3=self.Reward(s4)\n",
    "\n",
    "                s4_act_index=self.epsilon_greedy(s4)\n",
    "\n",
    "                SUM+=reward1\n",
    "                lenth+=1\n",
    "                \n",
    "                q1=self.Q[s1[0]][s1[1]][s1_act_index]\n",
    "                q4=self.Q[s4[0]][s4[1]][s4_act_index]\n",
    "\n",
    "                # TD_error=Q_now-TD_target\n",
    "                TD_error=q1-(reward1+pow(self.gamma,1)*reward2+pow(self.gamma,2)*reward3+pow(self.gamma,3)*q4)\n",
    "\n",
    "                self.Q[s1[0]][s1[1]][s1_act_index]-=self.alpha*TD_error\n",
    "                s1=s2.copy()\n",
    "\n",
    "                if self.game_map[s1[0]][s1[1]]==-100 or lenth>100:\n",
    "                    success.append(0)\n",
    "                    break\n",
    "                elif self.game_map[s1[0]][s1[1]]==10:\n",
    "                    success.append(1)\n",
    "                    break\n",
    "            \n",
    "            List.append(SUM)\n",
    "            if episode%1000==0:\n",
    "                self.epsilon*=0.99\n",
    "                Record.append(np.average(List[-1000:]))\n",
    "                print('Train ---- episode={}, ave_successes={:.3f} ave_reward={:.3f} '.format(\n",
    "                    episode, \n",
    "                    np.average(success[-1000:]),\n",
    "                    Record[-1])\n",
    "                )\n",
    "        return Record\n",
    "    \n",
    "    def get_guide(self) -> np.array:\n",
    "        guides=np.zeros(self.game_map.shape)\n",
    "        for i  in range(guides.shape[0]):\n",
    "            for j in range(guides.shape[1]):\n",
    "                guides[i][j]=np.argmax(self.Q[i][j])\n",
    "        return guides.astype(np.int32)\n",
    "\n",
    "        \n",
    "\n",
    "muti_sarsa=Muti_SARSA(game_map.game_map,actions)\n",
    "muti_List=muti_sarsa.update()\n",
    "muti_guide=muti_sarsa.get_guide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(muti_List)\n",
    "plt.xlabel('episodes(x1000)')\n",
    "plt.ylabel('Reward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_map.display_gamemap_and_arrows(muti_guide)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "private",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
